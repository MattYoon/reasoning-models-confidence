{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "import pandas as pd\n",
    "from eval.chat_benchmarks.SimpleQA.judge_prompt import JUDGE_PROMPT\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def create_request_data(id, content):\n",
    "    data_template = {\"custom_id\": f\"request-{id}\", \n",
    "                    \"method\": \"POST\", \n",
    "                    \"url\": \"/v1/chat/completions\", \n",
    "                    \"body\": {\"model\": \"gpt-4.1-2025-04-14\", \n",
    "                            \"messages\": [{\"role\": \"user\", \"content\": content}]}}\n",
    "    return data_template\n",
    "\n",
    "def read_data(path):\n",
    "    data = json.load(open(path))\n",
    "    # data.keys()\n",
    "    data_key = list(data['results'].keys())[0]\n",
    "    data_ = data['results'][data_key]['examples']\n",
    "    df = pd.DataFrame(data_)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>model_think</th>\n",
       "      <th>model_output</th>\n",
       "      <th>model_confidence</th>\n",
       "      <th>grade_letter</th>\n",
       "      <th>correct</th>\n",
       "      <th>not_attempted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who is the author of al capone does my shirts?</td>\n",
       "      <td>['Gennifer Choldenko']</td>\n",
       "      <td>Okay, so I need to figure out who wrote the bo...</td>\n",
       "      <td>\\n\\n**Answer**: Gennifer Choldenko\\n**Confiden...</td>\n",
       "      <td>Better than even</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         question                 answers  \\\n",
       "0  Who is the author of al capone does my shirts?  ['Gennifer Choldenko']   \n",
       "\n",
       "                                         model_think  \\\n",
       "0  Okay, so I need to figure out who wrote the bo...   \n",
       "\n",
       "                                        model_output  model_confidence  \\\n",
       "0  \\n\\n**Answer**: Gennifer Choldenko\\n**Confiden...  Better than even   \n",
       "\n",
       "  grade_letter  correct  not_attempted  \n",
       "0            A        1              0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/home/dongkeun/ckl_r1/evalchemy/logs/final/nonambigqa_val_1k/confidence_no_trigger/deepseek-ai__DeepSeek-R1-Distill-Qwen-32B/results_2025-04-19T15-40-29.387192.json'\n",
    "df = read_data(path)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompts import PROMPT_UNCERTAINTY, PROMPT_LINEAR\n",
    "\n",
    "mode = 'uncertainty'\n",
    "\n",
    "if mode == 'linear':\n",
    "    PROMPT = PROMPT_LINEAR\n",
    "elif mode == 'uncertainty':\n",
    "    PROMPT = PROMPT_UNCERTAINTY\n",
    "else:\n",
    "    raise ValueError(\"Invalid mode selected.\")\n",
    "\n",
    "\n",
    "def apply_request_data(example):\n",
    "    prompt = PROMPT.format(question=example['question'], model_think=example['model_think'])\n",
    "    id = f'{mode}_{example.name}'\n",
    "    return create_request_data(id, prompt)\n",
    "\n",
    "request_data = df.apply(apply_request_data, axis=1)\n",
    "request_data.to_json('request_data/request_data.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Upload to OpenAI as if it were a file\n",
    "batch_input_file = client.files.create(\n",
    "    file=open(\"request_data/request_data.jsonl\", \"rb\"),\n",
    "    purpose=\"batch\"\n",
    ")\n",
    "\n",
    "batch_input_file_id = batch_input_file.id\n",
    "batch_info = client.batches.create(\n",
    "    input_file_id=batch_input_file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "        \"description\": f'{mode}_{path}'\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_680d60f68b808190afa308d3e7693fdc\n"
     ]
    }
   ],
   "source": [
    "print(batch_info.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alchemy-ckl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
